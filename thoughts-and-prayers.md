- When implementing the macro, test it with "Expand macro recursively"
- Use the `Fn` Type to check that the given function is pure (note that polymorphic functions have to be handled aswell)
- Error handling should be as comprehensible as possible to the end user (if possible use custom errors, if not, ensure at least that the right part of the code is highlighted)
- How do we hand the `tracing_*` arguments through to other prob functions being called?
  - Simple option: Any function call which takes arguments as a `prob` function would take is transformed during code analysis in the macro (Make `tracing_path` a new-type for that). Problem: How do we handle funky uses of functions?
- Clean up the trace after each iteration? Is this principally necessary or only for performance? (<--!!?)
- Implement more informed proposal functions
- Handle MCMC for a failed sample
- Simplify trace entry such that we have fewer bespoke enums for the distributions (-> `new_structure.rs`)
- Change the effect of `condition` to it simply adding `-INF` to the log-likelihood, rather than `FnProb` having a `Result` return type.
- Define correct kernels for distributions! They have to be symmetric around current state, right?
- Idea: Add macro that can be applied to enums such that a categorical distribution over the enum is a primitive (optionally non-uniform)
- Idea: Add optional parameter to `sample!` which gives a name to the location instead of the normal numbering
- Maybe add some kind of "Block Resimulation" MH? I.e. Instead of only changing one variable at a time in our MH implementation, we change a bunch at once, with the bunch being one "block". The blocks could be user picked (additional macro), or automatically detected?
- Factor out as much as possible from the MH implementation (i.e. the initial choice, the repetitions, etc.; We should end up with just a single MH step in a function)
- Refactor to immutable as much as possible, esp in the macros
